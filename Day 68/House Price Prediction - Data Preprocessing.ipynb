{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2098fbd",
   "metadata": {},
   "source": [
    "###  Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa5d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8f154",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5571b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "    Area (sq ft)  Bedrooms  Price ($1000s)\n",
      "0        2000.0       3.0             500\n",
      "1        1500.0       2.0             350\n",
      "2        1800.0       3.0             450\n",
      "3        2200.0       4.0             600\n",
      "4           NaN       3.0             400\n",
      "5        2500.0       5.0             750\n",
      "6        2700.0       NaN             800\n",
      "7        1600.0       2.0             300\n",
      "8        1400.0       2.0             280\n",
      "9        2100.0       4.0             650\n"
     ]
    }
   ],
   "source": [
    "# Simulated house price dataset \n",
    "data = { \n",
    "    'Area (sq ft)': [2000, 1500, 1800, 2200, np.nan, 2500, 2700, 1600, 1400, 2100], \n",
    "    'Bedrooms': [3, 2, 3, 4, 3, 5, np.nan, 2, 2, 4], \n",
    "    'Price ($1000s)': [500, 350, 450, 600, 400, 750, 800, 300, 280, 650] \n",
    "} \n",
    "df = pd.DataFrame(data) \n",
    "print(\"Original Dataset:\\n\", df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3dabb0",
   "metadata": {},
   "source": [
    "### Handle Missing Values using SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83b60ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after Handling Missing Values:\n",
      "    Area (sq ft)  Bedrooms  Price ($1000s)\n",
      "0   2000.000000  3.000000           500.0\n",
      "1   1500.000000  2.000000           350.0\n",
      "2   1800.000000  3.000000           450.0\n",
      "3   2200.000000  4.000000           600.0\n",
      "4   1977.777778  3.000000           400.0\n",
      "5   2500.000000  5.000000           750.0\n",
      "6   2700.000000  3.111111           800.0\n",
      "7   1600.000000  2.000000           300.0\n",
      "8   1400.000000  2.000000           280.0\n",
      "9   2100.000000  4.000000           650.0\n"
     ]
    }
   ],
   "source": [
    "# Define imputer (Replace NaN with column mean) \n",
    "imputer = SimpleImputer(strategy='mean') \n",
    " \n",
    "# Apply imputer to dataset \n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns) \n",
    " \n",
    "print(\"\\nDataset after Handling Missing Values:\\n\", df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e50b3",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e205109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Size: (8, 2)\n",
      "Testing Set Size: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Features and target variable \n",
    "X = df_imputed[['Area (sq ft)', 'Bedrooms']]  # Features \n",
    "y = df_imputed['Price ($1000s)']  # Target variable \n",
    " \n",
    "# Split data (80% training, 20% testing) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    " \n",
    "print(\"\\nTraining Set Size:\", X_train.shape) \n",
    "print(\"Testing Set Size:\", X_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0dfb22",
   "metadata": {},
   "source": [
    "### Feature Scaling using StandardScaler and MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6200f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized Data (First 3 rows):\n",
      " [[ 1.16736275  1.89175141]\n",
      " [-0.32819095 -0.45662965]\n",
      " [-1.52463391 -1.63082018]]\n",
      "\n",
      "Normalized Data (First 3 rows):\n",
      " [[0.81818182 1.        ]\n",
      " [0.36363636 0.33333333]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization (mean = 0, variance = 1) \n",
    "scaler_standard = StandardScaler() \n",
    "X_train_standardized = scaler_standard.fit_transform(X_train) \n",
    "X_test_standardized = scaler_standard.transform(X_test)\n",
    "\n",
    "# Normalization (Scaling between 0 and 1) \n",
    "scaler_minmax = MinMaxScaler() \n",
    "X_train_normalized = scaler_minmax.fit_transform(X_train) \n",
    "X_test_normalized = scaler_minmax.transform(X_test) \n",
    " \n",
    "print(\"\\nStandardized Data (First 3 rows):\\n\", X_train_standardized[:3]) \n",
    "print(\"\\nNormalized Data (First 3 rows):\\n\", X_train_normalized[:3]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
